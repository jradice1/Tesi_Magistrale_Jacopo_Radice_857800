{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CCOHA - Rake-Nltk.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOKCBHIgq86a"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "root_dir = \"/content/drive/My Drive/\"\n",
        "base_dir = root_dir + 'Tesi/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjS60nRyh_Gf"
      },
      "source": [
        "!pip install rake-nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J15Oa-EMioCd"
      },
      "source": [
        "import nltk \n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx20RT3-RzWF"
      },
      "source": [
        "from itertools import chain\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGatZp9JrJGr"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "df = pd.read_csv(base_dir + 'downstream/ccoha2_preprocessed.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx_8E_ssN7bz"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXOeHRbX2v-n"
      },
      "source": [
        "RAKE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Def2REKSF3zT"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTR7pK6orza1"
      },
      "source": [
        "from rake_nltk import Rake\n",
        "\n",
        "r = Rake(min_length=2, max_length=4, language='english') # Uses stopwords for english from NLTK, and all puntuation characters."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_zY-oLe5Wlu"
      },
      "source": [
        "def rake_implement(x,r):\n",
        "     r.extract_keywords_from_text(x)\n",
        "     return r.get_ranked_phrases()\n",
        "\n",
        "df['keywords'] = df['text'].apply(lambda x: rake_implement(x,r))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3qNoZpOkAAr"
      },
      "source": [
        "MWE THRESHOLD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioOO5nk0kCOT"
      },
      "source": [
        "mwe_counter = Counter(chain.from_iterable(df['keywords'])) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POzDZZIdkLJF"
      },
      "source": [
        "df['keywords'] = [([j for j in i if mwe_counter[j] >= 5]) for i in df['keywords']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjm_yH65ReFJ"
      },
      "source": [
        "SUBSTITUTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARd0MFg6e4G0"
      },
      "source": [
        "import re\n",
        "\n",
        "for i in range(len(df)):\n",
        "  df['text'][i] = re.sub('('+'|'.join('\\\\b'+re.escape(g)+'\\\\b' for g in df['keywords'][i])+')', lambda m: m.group(0).replace(' ', '_'), df['text'][i], flags=re.I)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFgcTNYuFIYz"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWl9N9D89MkC"
      },
      "source": [
        "compression_opts = dict(method='zip', archive_name='RakeKeywords.csv')\n",
        "\n",
        "df['keywords'].to_csv('RakeKeywords.zip', index=False, compression=compression_opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlMgBUDPQ2Ju"
      },
      "source": [
        "compression_opts = dict(method='zip', archive_name='newCCOHA2_Rake.csv')\n",
        "\n",
        "df['text'].to_csv('newCCOHA2_Rake.zip', index=False, compression=compression_opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM3AoOEtyiCs"
      },
      "source": [
        "compression_opts = dict(method='zip', archive_name='preprocessed_Rake.csv')\n",
        "\n",
        "df.to_csv('preprocessed_Rake.zip', index=False, compression=compression_opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5H0MiinseiJ"
      },
      "source": [
        "TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkV8Ls3srARR"
      },
      "source": [
        "for i in range(len(df)):\n",
        "  df['text'][i]=df['text'][i].lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB1urhTa5-kS"
      },
      "source": [
        "df['token']=\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7THcg3Jo7LsK"
      },
      "source": [
        "def remove_p(text):\n",
        "    text  = \"\".join([char for char in text if char not in punct])\n",
        "    return text\n",
        "\n",
        "df['token'] = df['text'].apply(lambda x: remove_p(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppMthrJsIhYz"
      },
      "source": [
        "# tokenize sentences in corpus\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "tokenized_corpus = [wpt.tokenize(document) for document in df['text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsymuYO4nCU1"
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfvhRSOKnHl8"
      },
      "source": [
        "w2v_model = Word2Vec(size=300,\n",
        "                     negative=5,\n",
        "                     workers=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJUm7qqLnJyq"
      },
      "source": [
        "w2v_model.build_vocab(tokenized_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjVTt_dqnQmM"
      },
      "source": [
        "w2v_model.train(tokenized_corpus, total_examples=w2v_model.corpus_count, epochs=50, report_delay=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8Pvo45Iqa_o"
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"new_york\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgW1oqCcGNqE"
      },
      "source": [
        "w2v_model.wv.doesnt_match(['car', 'new_york', 'city'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jadsbMKeTI4"
      },
      "source": [
        "w2v_model.wv.save_word2vec_format('newText_Rake.txt', binary=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}