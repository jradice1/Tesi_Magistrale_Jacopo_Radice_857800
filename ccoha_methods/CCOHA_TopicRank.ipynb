{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CCOHA - TopicRank.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4JHcjxRDVrP"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "root_dir = \"/content/drive/My Drive/\"\n",
        "base_dir = root_dir + 'Tesi/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnS0GC62Dga7"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "df = pd.read_csv(base_dir + 'downstream/ccoha2_preprocessed.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z01LMQRtWpVP"
      },
      "source": [
        "!pip install git+https://github.com/boudinfl/pke.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_V0J1BKW0E6"
      },
      "source": [
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import pke"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11xJWFcnctOw"
      },
      "source": [
        "import spacy\n",
        "!python -m spacy download en\n",
        "nlp = spacy.load(\"en\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhaOh-zKSdkb"
      },
      "source": [
        "from itertools import chain\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa0hIBQjxmuB"
      },
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHd21hIkCw4i"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEKDj-mgDvjx"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A5bIWrwYeLr"
      },
      "source": [
        "TOPICRANK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7JLMU_rXND3"
      },
      "source": [
        "# select the longest sequences of nouns and adjectives, that do\n",
        "# not contain punctuation marks or stopwords as candidates.\n",
        "pos = {'NOUN', 'PROPN', 'ADJ'}\n",
        "stoplist = list(string.punctuation)\n",
        "stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "stoplist += stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAndHK2LQNRW"
      },
      "source": [
        "def extract_keyphrases(caption, n):\n",
        "    extractor = pke.unsupervised.TopicRank()\n",
        "    extractor.load_document(caption)\n",
        "    extractor.candidate_selection(pos = pos, stoplist=stoplist)\n",
        "    extractor.candidate_weighting(threshold=0.74, method='average')\n",
        "    keyphrases = extractor.get_n_best(n=n, stemming=False)\n",
        "    return(keyphrases)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvO_Hp1SQx0K"
      },
      "source": [
        "df['keywords'] = df.progress_apply(lambda row: (extract_keyphrases(row['text'], 10)),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvgVZDd8Q4pj"
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V03Og4YDsXi"
      },
      "source": [
        "# IF MWE ALREADY EXTRACTED\n",
        "\n",
        "import pandas as pd \n",
        "\n",
        "df = pd.read_csv(base_dir + 'downstream/checkpoints/checkpointCCOHA2_topicrank.csv', converters={'keywords': eval})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF8AIn0uOLGH"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGZ-itoqSi7h"
      },
      "source": [
        "keywords_without_unigrams = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2kWQEj_Se1l"
      },
      "source": [
        "for i in range(len(df)):\n",
        "  for kw in df['keywords'][i]:\n",
        "    if(' ' in kw[0]):\n",
        "        keywords_without_unigrams.append(kw[0])\n",
        "  df['keywords'][i]=keywords_without_unigrams\n",
        "  keywords_without_unigrams = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuPYY7ZBTIJM"
      },
      "source": [
        "df['keywords']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3qNoZpOkAAr"
      },
      "source": [
        "MWE THRESHOLD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioOO5nk0kCOT"
      },
      "source": [
        "mwe_counter = Counter(chain.from_iterable(df['keywords'])) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POzDZZIdkLJF"
      },
      "source": [
        "df['keywords'] = [([j for j in i if mwe_counter[j] >= 5]) for i in df['keywords']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VacmURh9TKSv"
      },
      "source": [
        "SUBSTITUTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOo29u0UTL4t"
      },
      "source": [
        "for i in range(len(df)):\n",
        "  df['text'][i] = re.sub('('+'|'.join('\\\\b'+re.escape(g)+'\\\\b' for g in df['keywords'][i])+')', lambda m: m.group(0).replace(' ', '_'), df['text'][i], flags=re.I)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhuY-h0AMGen"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlMgBUDPQ2Ju"
      },
      "source": [
        "compression_opts = dict(method='zip', archive_name='newCCOHA2_topicrank.csv')\n",
        "\n",
        "df['text'].to_csv('newCCOHA2_topicrank.zip', index=False, compression=compression_opts)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}